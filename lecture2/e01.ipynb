{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7f9685",
   "metadata": {},
   "source": [
    "### E01\n",
    "Train a **trigram language model**, i.e. take two characters as an input to predict the 3rd one. \n",
    "\n",
    "Feel free to use either counting or a neural net. \n",
    "\n",
    "Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6276b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total names 32033\n",
      "2 15\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a list\n",
    "with open('names.txt', 'r') as file:\n",
    "    names = file.read().split()\n",
    "\n",
    "print('Total names:', len(names))\n",
    "print(min(len(item) for item in names), max(len(item) for item in names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710ff933",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize a zero count 3D tensor. Keep the data type as int for count\n",
    "N = torch.zeros(27, 27, 27, dtype=torch.int)\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ac617b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Form stoi and itos\n",
    "vocab = sorted(list(set(''.join(names))))\n",
    "stoi = {s: i+1 for i, s in enumerate(vocab)}\n",
    "stoi['.'] = 0\n",
    "itos = {stoi[s]: s for s in stoi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9fb5c8",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Filling in the count matrix N\n",
    "for name in names:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        N[stoi[ch1], stoi[ch2], stoi[ch3]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b60986",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, 207, 190,  31, 366,  55,  21,  17,  91, 154,  27,  75, 632, 384,\n",
       "        623,  10,  17,   9, 482, 194,  72, 152, 243,   6,  27, 173, 152],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f75ba",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0469, 0.0431, 0.0070, 0.0830, 0.0125, 0.0048, 0.0039, 0.0206,\n",
       "         0.0349, 0.0061, 0.0170, 0.1433, 0.0871, 0.1413, 0.0023, 0.0039, 0.0020,\n",
       "         0.1093, 0.0440, 0.0163, 0.0345, 0.0551, 0.0014, 0.0061, 0.0392, 0.0345]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test: Calculating probability for just one row: names starting with '.a'\n",
    "p = N[0, 1, :].float()\n",
    "\n",
    "p /= p.sum()\n",
    "\n",
    "p, p.sum() # sum of a row should be 1 if calculated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327c1ed",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Calculating probability for all the possibilities\n",
    "P = (N+1).float()\n",
    "\n",
    "P /= P.sum(2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9488c64",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0002, 0.0469, 0.0430, 0.0072, 0.0827, 0.0126, 0.0050, 0.0041, 0.0207,\n",
       "        0.0349, 0.0063, 0.0171, 0.1427, 0.0868, 0.1406, 0.0025, 0.0041, 0.0023,\n",
       "        0.1089, 0.0439, 0.0165, 0.0345, 0.0550, 0.0016, 0.0063, 0.0392, 0.0345])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is almost identical to probability for just one row: names starting with '.a' that we calculated earlier\n",
    "# Difference because of normalization using +1 in the block above\n",
    "P[0, 1, :] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9812e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isronna', 'blealinawtt', 'cha', 'ubreedaneviya', 'zetaya']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g = torch.Generator().manual_seed(2147483647) # optional to generate same names for every execution\n",
    "\n",
    "# Generating random names\n",
    "out_names = []\n",
    "for _ in range(5):\n",
    "    ind1 = 0\n",
    "    ind2 = 0\n",
    "    curr = []\n",
    "    while True:\n",
    "        # P = N[ind].float()/sum(N[ind])\n",
    "        ind3 = torch.multinomial(P[ind1, ind2], num_samples=1).item()\n",
    "        # P[ind1, ind2, ind3] is the real probability\n",
    "        if ind3 == 0:\n",
    "            out_names.append(''.join(curr))\n",
    "            break\n",
    "        curr.append(itos[ind3])\n",
    "        ind1, ind2 = ind2, ind3\n",
    "\n",
    "out_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89f39b09",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_trigrams=196113\n",
      "log_likelihood=-410480.1699063033\n",
      "nll=2.0930798565434383\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss function\n",
    "\n",
    "log_likelihood = 0.0 # sum of logs\n",
    "total_trigrams = 0\n",
    "for word in names:\n",
    "    word = ['.'] + list(word) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
    "        ind1 = stoi[ch1]\n",
    "        ind2 = stoi[ch2]\n",
    "        ind3 = stoi[ch3]\n",
    "        prob = P[ind1, ind2, ind3]\n",
    "        logprob = torch.log(prob) # This is more negative on lower probabilities\n",
    "        # print(ch1+ch2+ch3, f'{prob:.4f}', f'{logprob:.4f}')\n",
    "        log_likelihood += logprob.item()\n",
    "        total_trigrams += 1\n",
    "\n",
    "nll = -log_likelihood # Goal is to minimize loss function\n",
    "nll /= total_trigrams # in practice we normalize it by total number of bigrams\n",
    "\n",
    "print(f'{total_trigrams=}')\n",
    "print(f'{log_likelihood=}')\n",
    "print(f'{nll=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef4e35",
   "metadata": {},
   "source": [
    "### Neural network framework\n",
    "\n",
    "- Initialize xs ( 27 * 27 ) and corresponding ys ( 27 )\n",
    "- Initialize weights with normalized normal values. Dimensions should be 27 * 27. Let's keep number of neurons to be 27 as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3039a9a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Populate training data\n",
    "xs, ys = [], []\n",
    "for name in names:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        xs.append([stoi[ch1], stoi[ch2]])\n",
    "        ys.append(stoi[ch3])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2bd2c14",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196113, 2]) torch.Size([196113])\n",
      "tensor([0, 5])\n",
      ". e m\n"
     ]
    }
   ],
   "source": [
    "print(xs.shape, ys.shape)\n",
    "print(xs[0])\n",
    "print(itos[xs[0, 0].item()], itos[xs[0, 1].item()], itos[ys[0].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "91d67a52",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# One hot encoding of the inputs\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # casting to float32 to match dtype of Weight\n",
    "xenc = xenc.view(xenc.shape[0], 2*27) \n",
    "yenc = F.one_hot(ys, num_classes=27).float()\n",
    "\n",
    "num = ys.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5b1499b7",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(27*2, 27, generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "88c08e80",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196113, 54]) torch.Size([54, 27])\n"
     ]
    }
   ],
   "source": [
    "print(xenc.shape, W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "19974094",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "logits = (xenc @ W)\n",
    "counts = logits.exp()\n",
    "# Normalize the count to get probability distribution\n",
    "probs = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "732dbc79",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196113, 27])\n",
      "tensor(1.0000, grad_fn=<SumBackward0>) 196113\n"
     ]
    }
   ],
   "source": [
    "print(probs.shape)\n",
    "\n",
    "print(probs[0].sum(), num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a507858e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13,  1,  ..., 26, 24,  0])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(num)\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b80d5a88",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.186271667480469\n"
     ]
    }
   ],
   "source": [
    "loss = -probs[torch.arange(num), ys].log().mean()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9a098755",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196113, 27])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fefc50e2",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austai\n",
      "ayaha\n",
      "aivethaay\n",
      "na\n",
      "auliakselirachaniolin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/_5c22x614_d4cb5qrlyt0rhh0000gn/T/ipykernel_70031/475452532.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xenc1 = F.one_hot(torch.tensor(pair), num_classes=27).float()\n"
     ]
    }
   ],
   "source": [
    "## Sampling\n",
    "for _ in range(5):\n",
    "    curr = []\n",
    "    ind1, ind2 = 0, 0\n",
    "    while True:\n",
    "        # ind3 = torch.multinomial(probs[ind1, ind2], num_samples=1).item()\n",
    "        pair = torch.tensor([[ind1, ind2]])\n",
    "        xenc1 = F.one_hot(torch.tensor(pair), num_classes=27).float()\n",
    "        xenc1 = xenc1.view(1, 2*27) \n",
    "        logit = xenc1 @ W\n",
    "        counts = logit.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True) # probablity of next character\n",
    "        # Sample\n",
    "        ind3 = torch.multinomial(p, num_samples=1, generator=g, replacement=True).item()\n",
    "        if ind3 == 0:\n",
    "            break\n",
    "        curr.append(itos[ind3])\n",
    "        ind1, ind2 = ind2, ind3\n",
    "    print(''.join(curr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "60f98c05",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2448902130126953\n",
      "2.2448506355285645\n",
      "2.2448103427886963\n",
      "2.2447710037231445\n",
      "2.244731903076172\n",
      "2.2446930408477783\n",
      "2.244654655456543\n",
      "2.2446165084838867\n",
      "2.2445785999298096\n",
      "2.2445411682128906\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    # Forward pass\n",
    "    logits = (xenc @ W)\n",
    "    counts = logits.exp()\n",
    "    # Normalize the count to get probability distribution\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "\n",
    "    # print(torch.arange(num))\n",
    "    # print(ys.shape)\n",
    "    # print(logits.shape, probs.shape)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b453350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
