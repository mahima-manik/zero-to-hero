{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c6cffb",
   "metadata": {},
   "source": [
    "### E02\n",
    "Split up the dataset randomly into 80% train set, 10% dev set, 10% test set. \n",
    "\n",
    "Train the bigram and trigram models only on the training set. \n",
    "\n",
    "Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade770d",
   "metadata": {},
   "source": [
    "### Setting up datasets\n",
    "- Load all the names into the list\n",
    "- Split the list into 80% train set, 10% dev set, 10% test set\n",
    "- Form stoi and itos dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01f6ac7f",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total names: 32033\n",
      "2 15\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a list\n",
    "with open('names.txt', 'r') as file:\n",
    "    names = file.read().split()\n",
    "\n",
    "print('Total names:', len(names))\n",
    "print(min(len(item) for item in names), max(len(item) for item in names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5eec7ec8",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Splitting names into 80% train set, 10% dev set, 10% test set\n",
    "import random\n",
    "\n",
    "random.shuffle(names) # Shuffles the list in-place\n",
    "\n",
    "split_1, split_2 = int(0.8*len(names)), int(0.9*len(names))\n",
    "train_list = names[:split_1]\n",
    "dev_list = names[split_1:split_2]\n",
    "test_list = names[split_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27b60a29",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 79.998751 %\n",
      "Dev set: 9.999063 %\n",
      "Test set: 10.002185 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set: {len(train_list)/len(names)*100.:4f} %')\n",
    "print(f'Dev set: {len(dev_list)/len(names)*100.:4f} %')\n",
    "print(f'Test set: {len(test_list)/len(names)*100.:4f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "87c8fca3",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Form stoi and itos\n",
    "vocab = sorted(list(set(''.join(names))))\n",
    "stoi = {s: i+1 for i, s in enumerate(vocab)}\n",
    "stoi['.'] = 0\n",
    "itos = {stoi[s]: s for s in stoi}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2798b08a",
   "metadata": {},
   "source": [
    "### Bigram: training\n",
    "- Perform Gradient descent and update weights only based on training list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "417d50a8",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Preparing bigrams\n",
    "xs, ys = [], []\n",
    "for name in train_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for xi, yi in zip(name, name[1:]):\n",
    "        xs.append(stoi[xi])\n",
    "        ys.append(stoi[yi])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "# Encoding the inputs\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "yenc = F.one_hot(ys, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d519ea78",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W_bigram = torch.randn(27, 27, generator=g, requires_grad=True)\n",
    "logits = (xenc @ W_bigram)\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "825a5112",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.759140729904175\n",
      "3.3714535236358643\n",
      "3.1542441844940186\n",
      "3.0203638076782227\n",
      "2.9275906085968018\n",
      "2.8602118492126465\n",
      "2.809485673904419\n",
      "2.7698166370391846\n",
      "2.7377521991729736\n",
      "2.7111473083496094\n",
      "2.688631296157837\n",
      "2.6692991256713867\n",
      "2.6525282859802246\n",
      "2.6378684043884277\n",
      "2.6249759197235107\n",
      "2.613579273223877\n",
      "2.603454351425171\n",
      "2.5944154262542725\n",
      "2.5863077640533447\n",
      "2.579000473022461\n",
      "2.572385311126709\n",
      "2.566370725631714\n",
      "2.560879945755005\n",
      "2.5558481216430664\n",
      "2.551220417022705\n",
      "2.546949625015259\n",
      "2.542996883392334\n",
      "2.539328098297119\n",
      "2.535914182662964\n",
      "2.5327305793762207\n",
      "2.529755115509033\n",
      "2.5269699096679688\n",
      "2.524357557296753\n",
      "2.521904230117798\n",
      "2.519596815109253\n",
      "2.517423391342163\n",
      "2.515374183654785\n",
      "2.513439416885376\n",
      "2.511610507965088\n",
      "2.5098795890808105\n",
      "2.50823974609375\n",
      "2.5066845417022705\n",
      "2.5052077770233154\n",
      "2.5038044452667236\n",
      "2.5024688243865967\n",
      "2.50119686126709\n",
      "2.4999845027923584\n",
      "2.4988279342651367\n",
      "2.497722864151001\n",
      "2.496666669845581\n",
      "2.4956560134887695\n",
      "2.4946885108947754\n",
      "2.4937610626220703\n",
      "2.4928712844848633\n",
      "2.4920172691345215\n",
      "2.491197347640991\n",
      "2.4904086589813232\n",
      "2.489650249481201\n",
      "2.488919734954834\n",
      "2.488215923309326\n",
      "2.4875376224517822\n",
      "2.4868834018707275\n",
      "2.4862518310546875\n",
      "2.4856419563293457\n",
      "2.4850523471832275\n",
      "2.484482526779175\n",
      "2.483931303024292\n",
      "2.4833977222442627\n",
      "2.4828803539276123\n",
      "2.4823801517486572\n",
      "2.4818947315216064\n",
      "2.481423854827881\n",
      "2.4809672832489014\n",
      "2.4805240631103516\n",
      "2.480093479156494\n",
      "2.479675531387329\n",
      "2.47926926612854\n",
      "2.4788739681243896\n",
      "2.4784903526306152\n",
      "2.478116512298584\n",
      "2.477752923965454\n",
      "2.4773988723754883\n",
      "2.4770543575286865\n",
      "2.4767184257507324\n",
      "2.476391315460205\n",
      "2.4760727882385254\n",
      "2.475762128829956\n",
      "2.475458860397339\n",
      "2.475163459777832\n",
      "2.474874973297119\n",
      "2.4745936393737793\n",
      "2.474318742752075\n",
      "2.474050760269165\n",
      "2.4737889766693115\n",
      "2.4735329151153564\n",
      "2.473283290863037\n",
      "2.473038911819458\n",
      "2.4728004932403564\n",
      "2.472566843032837\n",
      "2.472338914871216\n"
     ]
    }
   ],
   "source": [
    "num = ys.nelement() # number of examples\n",
    "\n",
    "# Gradient descent\n",
    "for _ in range(100):\n",
    "    # Forward pass\n",
    "    logits = xenc @ W_bigram # predicted log counts\n",
    "\n",
    "    # softmax (next two lines)\n",
    "    counts = logits.exp() # predicted counts\n",
    "    probs = counts / counts.sum(1, keepdims=True) # calculating probablities\n",
    "    \n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "\n",
    "    print(loss.item())\n",
    "\n",
    "    # Backward pass\n",
    "    W_bigram.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    W_bigram.data += -50 * W_bigram.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ef347",
   "metadata": {},
   "source": [
    "### Bigram: loss on dev and test sets\n",
    "- Prepare xs & corresponding ys dataset on dev & test\n",
    "- Evaluate loss of Dev set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5ab1e34e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "xs_dev, xs_test, ys_dev, ys_test = [], [], [], []\n",
    "for name in dev_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2 in zip(name, name[1:]):\n",
    "        xs_dev.append(stoi[ch1])\n",
    "        ys_dev.append(stoi[ch2])\n",
    "\n",
    "for name in test_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2 in zip(name, name[1:]):\n",
    "        xs_test.append(stoi[ch1])\n",
    "        ys_test.append(stoi[ch2])\n",
    "\n",
    "xs_dev = torch.tensor(xs_dev)\n",
    "ys_dev = torch.tensor(ys_dev)\n",
    "xs_test = torch.tensor(xs_test)\n",
    "ys_test = torch.tensor(ys_test)\n",
    "\n",
    "num_dev = len(xs_dev)\n",
    "num_test = len(xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b0bb8cdd",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182521, 27])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3053983b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dev_loss = -probs[torch.arange(num_dev), ys_dev].log().mean()\n",
    "test_loss = -probs[torch.arange(num_test), ys_test].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "725ac371",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.31862473487854 3.3068392276763916\n"
     ]
    }
   ],
   "source": [
    "print(dev_loss.item(), test_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c3705",
   "metadata": {},
   "source": [
    "### Trigrams: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb6bf16d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "xs_train, ys_train = [], []\n",
    "for name in train_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        xs_train.append([stoi[ch1], stoi[ch2]])\n",
    "        ys_train.append(stoi[ch3])\n",
    "\n",
    "xs_train = torch.tensor(xs_train)\n",
    "ys_train = torch.tensor(ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84bed82",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# One hot encoding of the inputs\n",
    "import torch.nn.functional as F\n",
    "xenc_train = F.one_hot(xs_train, num_classes=27).float() # casting to float32 to match dtype of Weight\n",
    "xenc_train = xenc_train.view(xenc_train.shape[0], 2*27) \n",
    "yenc_train = F.one_hot(ys_train, num_classes=27).float()\n",
    "\n",
    "num_train = ys_train.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "220f8f93",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W_tri = torch.randn(27*2, 27, generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8e44e072",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5036652088165283\n",
      "2.4992551803588867\n",
      "2.4950172901153564\n",
      "2.490922451019287\n",
      "2.486955404281616\n",
      "2.483107805252075\n",
      "2.4793732166290283\n",
      "2.4757466316223145\n",
      "2.4722235202789307\n",
      "2.468799114227295\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    # Forward pass\n",
    "    logits = (xenc_train @ W_tri)\n",
    "    counts = logits.exp()\n",
    "    # Normalize the count to get probability distribution\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "\n",
    "    # print(torch.arange(num))\n",
    "    # print(ys.shape)\n",
    "    # print(logits.shape, probs.shape)\n",
    "    loss = -probs[torch.arange(num_train), ys_train].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    W_tri.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights\n",
    "    W_tri.data += -10 * W_tri.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792b579",
   "metadata": {},
   "source": [
    "### Trigram: loss on dev and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "82bf2b83",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "xs_dev_tri, xs_test_tri, ys_dev_tri, ys_test_tri = [], [], [], []\n",
    "for name in dev_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        xs_dev_tri.append([stoi[ch1], stoi[ch2]])\n",
    "        ys_dev_tri.append(stoi[ch3])\n",
    "\n",
    "for name in test_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        xs_test_tri.append([stoi[ch1], stoi[ch2]])\n",
    "        ys_test_tri.append(stoi[ch3])\n",
    "\n",
    "xs_dev_tri = torch.tensor(xs_dev_tri)\n",
    "ys_dev_tri = torch.tensor(ys_dev_tri)\n",
    "xs_test_tri = torch.tensor(xs_test_tri)\n",
    "ys_test_tri = torch.tensor(ys_test_tri)\n",
    "\n",
    "num_dev_tri = len(ys_dev_tri)\n",
    "num_test_tri = len(ys_test_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "99615845",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dev_loss_tri = -probs[torch.arange(num_dev_tri), ys_dev_tri].log().mean()\n",
    "test_loss_tri = -probs[torch.arange(num_test_tri), ys_test_tri].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eea507b0",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev loss on trigrams: 3.237778425216675\n",
      "Test loss on trigrams: 3.236469030380249\n"
     ]
    }
   ],
   "source": [
    "print('Dev loss on trigrams:', dev_loss_tri.item())\n",
    "print('Test loss on trigrams:', test_loss_tri.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
