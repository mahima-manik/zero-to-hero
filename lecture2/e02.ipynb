{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c6cffb",
   "metadata": {},
   "source": [
    "### E02\n",
    "Split up the dataset randomly into 80% train set, 10% dev set, 10% test set. \n",
    "\n",
    "Train the bigram and trigram models only on the training set. \n",
    "\n",
    "Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f6ac7f",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total names: 32033\n",
      "2 15\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a list\n",
    "with open('names.txt', 'r') as file:\n",
    "    names = file.read().split()\n",
    "\n",
    "print('Total names:', len(names))\n",
    "print(min(len(item) for item in names), max(len(item) for item in names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eec7ec8",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Splitting names into 80% train set, 10% dev set, 10% test set\n",
    "import random\n",
    "\n",
    "random.shuffle(names) # Shuffles the list in-place\n",
    "\n",
    "split_1, split_2 = int(0.8*len(names)), int(0.9*len(names))\n",
    "train_list = names[:split_1]\n",
    "dev_list = names[split_1:split_2]\n",
    "test_list = names[split_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b60a29",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 79.998751 %\n",
      "Dev set:, 9.999063 %\n",
      "Test set:, 10.002185 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set: {len(train_list)/len(names)*100.:4f} %')\n",
    "print(f'Dev set: {len(dev_list)/len(names)*100.:4f} %')\n",
    "print(f'Test set: {len(test_list)/len(names)*100.:4f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c8fca3",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Form stoi and itos\n",
    "vocab = sorted(list(set(''.join(names))))\n",
    "stoi = {s: i+1 for i, s in enumerate(vocab)}\n",
    "stoi['.'] = 0\n",
    "itos = {stoi[s]: s for s in stoi}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3aa63",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "417d50a8",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Preparing bigrams\n",
    "xs, ys = [], []\n",
    "for name in train_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for xi, yi in zip(name, name[1:]):\n",
    "        xs.append(stoi[xi])\n",
    "        ys.append(stoi[yi])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "# Encoding the inputs\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "yenc = F.one_hot(ys, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d519ea78",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W_bigram = torch.randn(27, 27, generator=g, requires_grad=True)\n",
    "logits = (xenc @ W_bigram)\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825a5112",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758641004562378\n",
      "3.3703830242156982\n",
      "3.153103828430176\n",
      "3.019284963607788\n",
      "2.9265940189361572\n",
      "2.8592894077301025\n",
      "2.8086068630218506\n",
      "2.7689595222473145\n",
      "2.7369072437286377\n",
      "2.7103095054626465\n"
     ]
    }
   ],
   "source": [
    "num = ys.nelement() # number of examples\n",
    "\n",
    "# Gradient descent\n",
    "for _ in range(10):\n",
    "    # Forward pass\n",
    "    logits = xenc @ W_bigram # predicted log counts\n",
    "\n",
    "    # softmax (next two lines)\n",
    "    counts = logits.exp() # predicted counts\n",
    "    probs = counts / counts.sum(1, keepdims=True) # calculating probablities\n",
    "    \n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "\n",
    "    print(loss.item())\n",
    "\n",
    "    # Backward pass\n",
    "    W_bigram.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    W_bigram.data += -50 * W_bigram.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ab1e34e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Evaluate loss of Dev set and test set\n",
    "# - prepare dataset on dev\n",
    "\n",
    "xs_dev, xs_test, ys_dev, ys_test = [], [], [], []\n",
    "for name in dev_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2 in zip(name, name[1:]):\n",
    "        xs_dev.append(stoi[ch1])\n",
    "        ys_dev.append(stoi[ch2])\n",
    "\n",
    "for name in test_list:\n",
    "    name = ['.'] + list(name) + ['.']\n",
    "    for ch1, ch2 in zip(name, name[1:]):\n",
    "        xs_test.append(stoi[ch1])\n",
    "        ys_test.append(stoi[ch2])\n",
    "\n",
    "xs_dev = torch.tensor(xs_dev)\n",
    "ys_dev = torch.tensor(ys_dev)\n",
    "xs_test = torch.tensor(xs_test)\n",
    "ys_test = torch.tensor(ys_test)\n",
    "\n",
    "num_dev = len(xs_dev)\n",
    "num_test = len(xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0bb8cdd",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182719, 27])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053983b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dev_loss = -probs[torch.arange(num_dev), ys_dev].log().mean()\n",
    "test_loss = -probs[torch.arange(num_test), ys_test].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ac371",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loss.item(), \u001b[43mtest\u001b[49m.item()\n",
      "\u001b[31mNameError\u001b[39m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "print(loss.item(), test.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99615845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
